# ü§ñ Gu√≠a AIOps: Predicci√≥n de Capacidad con BigQuery AutoML

Este laboratorio muestra el flujo completo ("End-to-End") para crear un modelo de **Regresi√≥n con AutoML** en BigQuery.

El objetivo es predecir un valor num√©rico (porcentaje de CPU) bas√°ndonos en m√©tricas operativas complejas, dejando que Google pruebe y elija autom√°ticamente el mejor algoritmo.

---

## üìñ Entendiendo los Par√°metros de Entrenamiento

Cuando usas `AUTOML_REGRESSOR`, no est√°s eligiendo un algoritmo (como "√Årboles" o "Redes Neuronales"). Est√°s contratando a un "Robot Cient√≠fico de Datos" para que pruebe muchos por ti.

Aqu√≠ explicamos las opciones cr√≠ticas que usamos en la query `CREATE MODEL`:

### 1. `budget_hours` (Presupuesto de Tiempo)
> **Ejemplo:** `budget_hours = 1.0`

* **¬øQu√© es?** Es el tiempo m√°ximo (en horas) que le das a Google para entrenar y probar diferentes modelos.
* **¬øC√≥mo funciona?**
    * Google empezar√° a probar algoritmos (Linear, XGBoost, DNN...).
    * Si pones **1.0**, Google pasar√° 1 hora probando combinaciones. Al terminar la hora, se quedar√° con el "Ganador" y descartar√° el resto.
* **Coste:** Pagas por el tiempo de computaci√≥n reservado.
* **Recomendaci√≥n:**
    * Para pruebas/clase: **1.0** (el m√≠nimo suele ser suficiente para datasets peque√±os).
    * Para producci√≥n cr√≠tica: **2.0 - 5.0** (si quieres exprimir un 1-2% extra de precisi√≥n).

### 2. `input_label_cols` (La Meta)
> **Ejemplo:** `input_label_cols = ['cpu_usage_pct_target']`

* **¬øQu√© es?** Es la columna que contiene la **Respuesta Correcta** (el Target).
* **Importante:** Es lo que el modelo intentar√° adivinar en el futuro.

### 3. `optimization_objective` (Opcional)
> **Ejemplo:** `optimization_objective = 'MINIMIZE_RMSE'`

* **¬øQu√© es?** Le dice al robot qu√© m√©trica usar para decidir qui√©n gana.
    * **RMSE:** (Ra√≠z del Error Cuadr√°tico Medio). Penaliza mucho los errores grandes. Es el est√°ndar.
    * **MAE:** (Error Absoluto Medio). Trata todos los errores por igual.

---

## üõ†Ô∏è El Flujo Completo (SQL)

Sigue estos pasos en BigQuery para replicar el experimento.

### Paso 1: Generar Datos de Entrenamiento (Simulaci√≥n)
Creamos 2,000 minutos de historia de un servidor.
* **Correlaci√≥n:** M√°s Tr√°fico + M√°s Latencia + M√°s Errores = **CPU al rojo vivo**.

```sql
CREATE OR REPLACE TABLE `formacionaiops-476808.test.ops_capacity_metrics` AS

WITH GENERATOR AS (
  SELECT x FROM UNNEST(GENERATE_ARRAY(1, 2000)) AS x
),
RAW_DATA AS (
  SELECT
    timestamp_sub(CURRENT_TIMESTAMP(), INTERVAL x MINUTE) as metric_time,
    -- M√©tricas de entrada (Features)
    CAST(FLOOR(10 + RAND() * 500) AS INT64) as requests_per_sec,
    CAST(FLOOR(20 + RAND() * 2000) AS INT64) as avg_latency_ms,
    CAST(FLOOR(RAND() * 50) AS INT64) as error_log_count,
    IF(RAND() < 0.3, 'TRUE', 'FALSE') as is_backup_running,
    RAND() as ruido
  FROM GENERATOR
)

SELECT
  metric_time,
  requests_per_sec,
  avg_latency_ms,
  error_log_count,
  is_backup_running,
  
  -- Generamos el Target (CPU %) con una f√≥rmula l√≥gica + ruido
  LEAST(100, GREATEST(5, 
    (
      (requests_per_sec * 0.1)      -- Tr√°fico base
      + (avg_latency_ms * 0.02)     -- Latencia pesa poco
      + (error_log_count * 0.5)     -- Errores pesan mucho
      + CASE WHEN is_backup_running = 'TRUE' THEN 20 ELSE 0 END -- Backup a√±ade carga fija
    ) 
    + (ruido * 5)
  )) AS cpu_usage_pct_target

FROM RAW_DATA;

```

### Paso 2: Entrenar el Modelo (AutoML)
Lanzamos el entrenamiento.

Nota: Esto tardar√° aproximadamente 1 hora en completarse debido al budget_hours.


```
CREATE OR REPLACE MODEL `formacionaiops-476808.test.cpu_capacity_predictor`
OPTIONS(
  model_type = 'AUTOML_REGRESSOR',
  input_label_cols = ['cpu_usage_pct_target'], -- Queremos predecir % CPU
  budget_hours = 1.0                           -- Tiempo m√°ximo de entrenamiento
) AS
SELECT
  requests_per_sec,
  avg_latency_ms,
  error_log_count,
  is_backup_running,
  cpu_usage_pct_target
FROM
  `formacionaiops-476808.test.ops_capacity_metrics`;
```

### Paso 3: Simular Escenarios (Predicci√≥n)

Una vez termine el entrenamiento, usamos ML.PREDICT para preguntar: "¬øQu√© pasar√≠a s√≠...?"

```
SELECT
  *
FROM
  ML.PREDICT(MODEL `formacionaiops-476808.test.cpu_capacity_predictor`,
    (
      -- Escenario A: Tr√°fico Alto pero Sano (Latencia baja, sin errores)
      SELECT 
        'Escenario_A_TraficoSano' as scenario_id, 
        450 as requests_per_sec, 
        30 as avg_latency_ms, 
        0 as error_log_count, 
        'FALSE' as is_backup_running
      
      UNION ALL
      
      -- Escenario B: La "Tormenta Perfecta" (Tr√°fico medio, pero lento y con errores)
      SELECT 
        'Escenario_B_Incidente' as scenario_id, 
        200 as requests_per_sec, 
        1500 as avg_latency_ms,   -- Latencia alta
        40 as error_log_count,    -- Muchos logs de error
        'FALSE' as is_backup_running

      UNION ALL

      -- Escenario C: Backup Nocturno (Poco tr√°fico pero backup activo)
      SELECT 
        'Escenario_C_Backup' as scenario_id, 
        50 as requests_per_sec, 
        40 as avg_latency_ms,   
        0 as error_log_count,    
        'TRUE' as is_backup_running
    )
  );
```

###  üìä Interpretaci√≥n de Resultados
Ver√°s la columna predicted_cpu_usage_pct_target.

Escenario A: Predicci√≥n media (~50%). El modelo aprendi√≥ que el tr√°fico puro no es lo √∫nico que importa.

Escenario B: Predicci√≥n muy alta (~90%). El modelo aprendi√≥ que Errores + Latencia es una combinaci√≥n mortal para la CPU.


### OJOOOOO budget_hours

Lo ponemos por Seguridad Financiera y Operativa. Es tu "cintur√≥n de seguridad".

Control de Costes: Si Google cambiara el defecto ma√±ana a 24 horas y t√∫ lanzas el entrenamiento sin mirar, podr√≠as recibir una factura de cientos de d√≥lares por un experimento. Poner 1.0 te garantiza que nunca pagar√°s m√°s de 1 hora de computaci√≥n.

Gesti√≥n del Tiempo: Si est√°s en una clase o tienes prisa, quieres asegurarte de que el modelo no se quede "pensando" durante 6 horas buscando una mejora del 0.001% en precisi√≥n.